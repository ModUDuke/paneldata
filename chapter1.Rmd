rm---
title       : Introduction to Panel Data
description : This chapter will introduce you to analysis techniques with panel data




--- type:VideoExercise lang:arsd aspect_ratio:62.5 xp:50 skills:1 key:40491e0e85
## Introduction to Panel Data: Does the Death Penalty Reduce Homicides?
*** =video_link
//player.vimeo.com/video/226206272

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:529f2b036c
## Confounders in Cross-Sectional Data 
In the previous video, we studied whether the death penalty causes a reduction in homicide rates by comparing states that have the death penalty to states that don't have the death penalty. If we look at the relationship between homicide rates and the death penalty at a single point in time, many factors may confound this relationship. Which of the following would *not* necessarily confound a causal interpretation of the how the death penalty affects state homicide rates at a single point in time?
*** =instructions
- High rates of violence encourages states to instate a death penalty.
- States that have the death penalty tend to have lower education, and education reduces violent behavior.
- States that have the death penalty tend to have lower rates of mortality.
- States that don't have the death penalty also tend to legalize more recreational drugs, which pacifies people's violent behavior.
*** =sct
```{r}
msg1 = "If this were the case, we would probably find that states with the death penalty had higher rates of homicide regardless of whether the death penalty deterred homicide. Try again."
msg2 = "If this were the case, education would confound the relationship between having and not having the death penalty. We would expect that states with the death penalty have higher underlying homicide rates of homicide, so whatever deterrent effect of the death penalty that we estimated would be smaller than the true deterrent effect. Try again."
msg3 = "Correct! Unless we assumed that rates of homicide have a significant impact on a state's mortality rate, we would not expect mortality rates to confound the relationship between the death penalty and homicide rates."
msg4 = "If this were the case, legalized recreational drugs would confound the relationship between having and not having the death penalty. For example, if the death penalty deterred homicide rates, but had a smaller effect on homicide rates that than legalized recreational drugs, we would probably see a positive causal effect of the death penalty on homicide rates. Try again."
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:8c564a8661
## Longitudinal Analysis without a Comparison Group.
Say we found that states that established the death penalty had lower rates of homicide in later years. Would this be enough information to conclude that the death penalty lowered the effect of homicide? 
*** =instructions
- Yes
- No
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Correct! Even though states that established the death penalty had lower rates of homicide in later years, this could have been coincidental. What if rates of homicide were dropping everywhere for an entirely different reason? In order to establish causality, we would need to look at homicide trends in states that did not establish the death penalty. If homicide rates decreased consistently across all states, our findings would not support the hypothesis that the death penalty reduces rates of homicide."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```



--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:5d221a7ed2
## The Common Trends Assumption
*** =video_link
//player.vimeo.com/video/226208683


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:bfcf99d7c6
## Interpreting Longitudinal Outcomes
In the early 1950s, the mayor of Springfield, Oklahoma, noticed that his citizens had higher rates of diabetes than ever before. To combat diabetes, the mayor of Springfield implemented a permanent sales tax on all food items that contained corn syrup. Now, the mayor of Springfield's neighbor Laughterville is concerned about rates of diabetes in his state, and is considering implementing a tax on food items that contain corn syrup. To inform his decision, the mayor of Laughterville compares rates of diabetes (percentage of population) in Laughterville to rates of diabetes in Springfield over time. A table of the data is included below.

|     City      | 1950 | 1960 | 1970 | 1980 | 1990 | 2000 | 2010 |
|---------------|-----:|-----:|-----:|-----:|-----:|-----:|-----:|
| Springfield   |  .98 | 1.13 | 1.88 | 2.69 | 2.91 | 3.84 | 5.20 |
| Laughterville | 1.01 | 1.21 | 2.40 | 3.14 | 3.67 | 4.75 | 6.66 |

Based on this table, which conclusion about the effect of taxing corn syrup products on rates of diabetes seems most reasonable?

*** =instructions
- Taxes have no effect, given that rates of diabetes in Springfield were much higher following the implementation of the tax.
- Taxes have a negative effect on rates of diabetes (i.e. decreased rates of diabetes), given that rates of diabetes in Springfield were lower than those in Laughterville following the implementation of the - Taxes have a positive effect on rates of diabetes (i.e. increased rates of diabetes), given that rates of diabetes in Springfield were much higher following the implementation of the tax.
tax.*** =sct
```{r}
msg1 = "Not quite. Try comparing the outcomes of Springfield to Laughterville."
msg2 = "Correct! This is exactly how we interpret difference in differences outcomes. Even though Springfield had higher rates of diabetes following the implementation of its tax on corn syrup products, it appears that Springfield's rate diabetes grew at a smaller rate than in Laughterville."
msg3 = "Not quite. Try comparing the outcomes of Springfield to Laughterville."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2,msg3))
```


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:1019f22cf2
## Advantage of Longitudinal Data
What is the main advantage you get from studying a causal effect with longitudinal dataset rather than repeated cross-sectional datasets?
*** =instructions
- Systematic differences between the treatment and control group are less likely to confound the average treatment effect.
- You can see systematic changes across a population with time.
- It inherently uses a smaller sample of people, so fewer random differences should arise between datasets.
*** =sct
```{r}
msg1 = "Correct! This is especially the case when we use time-series data. Systematic differences between the treatment and control group are only important if we expect the treatment to have a difference effect on different types of people. For example, if it turned out that the death penalty was only a deterrent for homicide in states with high urban populations, but our treatment group only contained states with high rural populations, we would not see any causal effect of the death penalty on homicide rates."
msg2 = "Actually, you can see systematic changes across a population with time even with repeated cross sectional datasets. Try again."
msg3 = "This is close, but having larger samples is generally good for studying causal effects."
test_mc(correct = 1, feedback_msgs = c(msg1,msg2,msg3))
```


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:15a897d978
## Assumptions of Difference in Differences Analysis
What is the main assumption that we make when we study a causal effect by comparing trends among a treatment group with trends among a control group?
*** =instructions
- If there are no differences between the two groups, the null hypothesis is confirmed.
- If the control group has the same outcome as the treatment group, then the treatment has no effect.
- Any difference between the control group and the treatment group that is statistically significant is meaningful.
- Any difference in the trends we see among the treatment group and control groups are due to the treatment.

*** =sct
```{r}
msg1 = "This answer is deliberately vague but it's not really an 'assumption' that we make. Try again."
msg2 = "Almost. However, for this to be completely true, we would need to insert in front of the statement: 'controlling for spurious differences in the control group and the treatment group...' Try again."
msg3 = "This is simply not true; we can find statistically significant results that are not necessarily 'meaningful'"
msg4 = "Correct! If there is a different factor that causes trends in the treatment group to differ from the control group, our finding would be spurious."
test_mc(correct = 4, feedback_msgs = c(msg1,msg2,msg3,msg4))
```



--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:768ce0d1ab
## The Three Kinds of Panel Data
*** =video_link
//player.vimeo.com/video/226207544


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:625dd45a40
## Repeated cross-sectional data versus time-series data
When we have repeated cross-sectional data, we have a different sample at each time point. With this sort of data, we cannot estimate within person fixed effects or any difference in differences style outcome, as we only have a response from each surveyed individual at one separate time point. Nonetheless, why might repeated cross-sectional data be useful?

*** =instructions
- Because it increases your sample size.
- It can help reveal time trends among a population and outcome of interest.
- To remove bias that could result from generational differences across a population.
- It is cheaper than gathering longitudinal samples.
*** =sct
```{r}
msg1 = "This is sort of true, but not really the main reason people use repeated cross-sectional survey."
msg2 = "Correct!"
msg3 = "This is a possible advantage of repeated cross-sectional data, although it is relatively uncommon to have so many cross sections in a dataset that you could even pick up generational differences in outcomes (i.e. cohort effects). Try again."
msg4 = "This is sort of true, except it is still very expensive to conduct multiple cross-sectional surveys. Cost is less of an issue than is the difficulty in reaching out to individuals who took the survey before."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2,msg3,msg4))
```


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:0d9f8078a3
## Interpreting Longitudinal Outcomes II
During his fourth annual performance review, the CEO of gunsNguns.com asked for a bonus, noting that during his four years as CEO, the revenue of gunsNguns.com increased by $32m! Before the board of directors at gunsNguns.com made their final decision, they decided to examine sales data from similarly sized rivals across the past four years, listed below. 

|    Company     | Year 1 | Year 2 | Year 3 | Year 4 |
|----------------|-------:|-------:|-------:|-------:|
| gunsNguns.com  |  145m  |  153m  |  166m  |  177m  |
| Avg Competitor |  162m  |  174m  |  187m  |  205m  |

Based on this table, which conclusion about the effect of taxing corn syrup products on rates of diabetes seems most reasonable?

*** =instructions
- The CEO deserves a raise - a $32m increase in revenue is huge!
- The CEO deserves to be put on probation - he lied about how much he helped increase the revenue of gunsNguns.com!
- The CEO does not deserve a raise - a $32m increase in revenue is not large enough!
- The CEO deserves to be put in jail - he helped distribute so many guns!

*** =sct
```{r}
msg1 = "Try comparing the sales increase of gunsNguns.com to their competitors."
msg2 = "Whoops. His math was correct. Try again."
msg3 = "Correct! Most of the company's competitors had even greater increases in revenue over that time period. This probably reflects that there was an overall increase in demand for the type of goods sold by gunsNguns.com."
msg4 = "We probably should have mentioned that the CEO was only distributing guns in America. This answer is irrelevant. Try again!"
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```


--- type:NormalExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:67a27055aa
## Practice Preparing Longitudinal Data for Analysis
More often than not, publically available panel survey datasets are posted online in *wide format*, where each row corresponds to an individual survey respondent and each column corresponding to a single variable from a given wave of the dataset. For example, a dataset about people's body mass index (BMI) over time might have several columns for each respondent, labeled something like "BMI.Wave.1," "BMI.Wave.2," "BMI.Wave.3," etc. The problem is that many R functions that work with panel data (such as the graph in the previous problem) require your data to be in *long format*, where each unique variable corresponds to a single column (e.g. just "BMI"), and where each row corresponds to a specific respondent identification and a specific year that the response was collected. 

Many programs have been developed for converting particular popular datasets from wide to long format, but there are many cases where data analysts must develop these programs themselves. Let's handle a relatively basic example. Follow the notation below to convert the dataset, `wide.df` from *wide* to *long* format. 
*** =instructions
- Create a *long format* dataset called `long.df` that corresponds to the data in `wide.df`

*** =pre_exercise_code
```{r}
set.seed(1)
n=221
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
        qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
        base*round(x/base) 
    } 
#Dataframe
    wide.df<-data.frame(ID=1:n)
    wide.df$Diet.1995<-round(rtnorm(n,mean=2500,sd=300,min=1000,max=4000),0)
    wide.df$BMI.1995<-round(rtnorm(n,mean=25,sd=4,min=15,max=30)+wide.df$Diet.1995/1000,1)
    
    wide.df$Diet.1996<-wide.df$Diet.1995+round(rtnorm(n,mean=0,sd=100,min=-500,max=500),0)
    wide.df$BMI.1996<-wide.df$BMI.1995+ round(rtnorm(n,mean=0,sd=1,min=-5,max=5)+wide.df$Diet.1996/1000 - mean(wide.df$Diet.1996)/1000,1)
    
    wide.df$Diet.1997<-wide.df$Diet.1996+round(rtnorm(n,mean=0,sd=100,min=-500,max=500),0)
    wide.df$BMI.1997<-wide.df$BMI.1996+ round(rtnorm(n,mean=0,sd=1,min=-5,max=5)+wide.df$Diet.1997/1000 - mean(wide.df$Diet.1997)/1000,1)
    
    library(plm)
```
*** =sample_code
```{r}
# Let's examine our dataset to get a sense of it. Basically we have 121 distinct respondents, with information about their diets and BMIs in 1995, 1996, and 1997.
    str(wide.df)

# If we want to convert this data to long format, We basically want a dataset where each year of each variable is appeneded on top of each other, and where we have an indicator for ID and year. To start, make three separate datasets called "df1995", "df1996", and "df1997". Each of these datasets should the contain an "ID" column from wide.df, followed by a single Diet variable from the corresponding year, and a single and BMI variable from the corresponding year.
    df1995<-
    df1996<-
    df1997<-

# We want each of these dataframes to be composed of variables containing the same name. If you have not done so already, rename the rows of each column to "ID", "Diet", and "BMI", otherwise, delete the three lines below
    names(df1995)<-
    names(df1996)<-
    names(df1997)<-

# Now for each dataframe, create a variable titled "Year" that contains a number that contains the Year indicated by the data frame. 
    df1995$Year<-
    df1996$Year<-
    df1997$Year<-

# Create a dataframe called long.df, which appends df1995 on top of df1996 and df1997. You can either do this with two separate "rbind" functions, or with a "do.call" function.
    long.df<-
      
# Finally, sort the data by ID and Year so that the ID in the first three rows is ID1, and the Year in the first three rows is 1995, 1996, and 1997. This can be done with the subset and order functions. 
    long.df<-long.df[order(long.df$,long.df$),]
    
# If you did all of the above correctly, the following fixed effects model (more on those later in the unit) should produce a positive and statistically significant coefficient for the effect of Diet on BMI (i.e. individuals who ate more across waves tended to gain weight).
    summary(plm(BMI ~ Diet, data=long.df, index=c("ID", "Year"), model="within"))
    
```
*** =solution
```{r}
    df1995<-data.frame(ID=wide.df$ID,Diet=wide.df$Diet.1995,BMI=wide.df$BMI.1995)
    df1996<-data.frame(ID=wide.df$ID,Diet=wide.df$Diet.1996,BMI=wide.df$BMI.1996)
    df1997<-data.frame(ID=wide.df$ID,Diet=wide.df$Diet.1997,BMI=wide.df$BMI.1997)
    df1995$Year<-1995
    df1996$Year<-1996
    df1997$Year<-1997
    long.df<-do.call("rbind",list(df1995,df1996,df1997))
    long.df<-long.df[order(long.df$ID,long.df$Year),]
```
*** =sct
```{r}
test_object("wide.df")
success_msg("Good work! To convert datasets with lots of variables, you can apply the same logic to convert the variables more iteratively. For example, by create a dataframe of all variables that include the substring '1995', and creating new variable names that remove that substring. Nonetheless, the logic is for converting these data frames from wide to long format is identical.")
```


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:817f01d83c
## Effect of Immigration on Employment
*** =video_link
//player.vimeo.com/video/226206552

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:c02885efe0
## Effect of Immigration on Employment Question
Is it possible to use differences-in-differences to learn about causal effects if I only have data on the treatment group?
*** =instructions
- No
- Yes
*** =sct
```{r}
msg1 = "Correct! You must have data on a control group as well, because that is how you extract the common trend! The Mariel Boatlift case is a great example--David Card starts with data on unemployment rates in Miami. But that's not enough to learn about causality. So he constructs a control group of comparison cities from which he argues we can extract the common trend."
msg2 = "Try again"
test_mc(correct = 1, feedback_msgs = c(msg1,msg2))
```


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:ec875547d3
## Inferring Personal Motivations from Aggregate Trends
After reading David Card's article about how immigration has a negative effect on rates unemployment (i.e. immigration reduces unemployment), Bella decides to write an op-ed about these trends in her favorite magazine, "Psychology Tomorrow." Bella writes that immigration leads to decreased unemployment because seeing the struggles of immigrants motivates local business owners to create new jobs for migrants, even when such roles are unnecessary for their businesses. Is this a reasonable conclusion to draw from these trends?

*** =instructions
- Yes
- No

*** =sct
```{r}
msg1 = "Try again"
msg2 = "Correct! Bella is committing an ecological inference fallacy - she is interpreting statistical data about group trends to make inferences about individuals within that group. There are many possible mechanisms that are producing the association between migration and unemployment. We cannot make conclusions about which mechanisms are producing this trend without studying each one individually. In order to substantiate Bella's hypothesis, we would need to survey business owners in Miami and ask them why they decided to offer more jobs, or at the very least, rule out alternative explanations for why they offered more jobs."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```



--- type:NormalExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:c747fbb05d
## Practice implementing difference in differences models
The mayor of Sommersdale Ontario is interested in combatting homelessness in his city with a Housing First policy. This policy would have the city pay for cheap apartments for all homeless people with no-strings attached. Supporters of the Housing First policy claim that the majority of the costs in implementing the policy would be offset by the reduced of resources that the city would need to spend on homeless shelters, jail time, and emergency room visits for the chronically homeless. 

While the mayor of Sommersdale is convinced that the Housing First policy would substantially reduce rates of homelessness, he is uncertain whether implementing the program would substantially reduce other city expenditures on the homeless. As a preliminary analysis, the Mayor of Sommersdale gathered data on incarceration rates among 10 cities at two time points, 2005 and 2015, half of which implemented Housing First between 2009 and 2013. Conduct a difference in differences analysis with the dataset `Jail` to examine whether the Housing First policy reduced incarceration rates. Specifically:
*** =instructions
- Use a t.test to assess whether cities that eventually implemented the Housing First policy (`Implemented==1`) tended to have higher rates of incarceration (`rate`) in 2005 (`Year==2005`) than cities that had not implemented the Housing First Policy (`Implemented==0`)
- Use a t.test to assess whether cities that implemented the Housing First policy (`Implemented==1`) tended to have higher rates of incarceration (`rate`) in 2015 (`Year==2015`) than cities that had not implemented the Housing First Policy (`Implemented==0`)
- Use a difference in differences model to estimate whether cities that implemented the Housing First policy (`Implemented==1`) tended to have lower rates of incarceration than one would expect based on common trends.

*** =pre_exercise_code
```{r}
n=10
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
        qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
        base*round(x/base) 
    } 

set.seed(13)
#Dataframe with year 1
    Jail1<-data.frame(City=c("Moraine","Netarts","Oak City","Heritage Creek","Gallitzin","Trout Valley","Allendale","Boaz","Texanna","Ayer"),Year=2005,rate=round(rtnorm(n,mean=115,sd=50,min=50,max=200),0),Implemented=rbinom(10,1,.4))
    Jail1$rate<-ifelse(Jail1$Implemented==1, Jail1$rate+20,Jail1$rate)
#Dataframe with year 2
    Jail2<-data.frame(City=Jail1$City,Year=2015,Implemented=Jail1$Implemented)
#year 2 rate
    Jail2$rate<-Jail1$rate+Jail2$Implemented*(-20)+ round(rtnorm(n,mean=20,sd=10,min=0,max=50),0)
#Append data
    Jail<-rbind(Jail1,Jail2)
    Jail<-Jail[order(Jail$City,Jail$Year),]
    Jail$Year<-factor(Jail$Year)
    rm("Jail2")
    rm("Jail1")
    
```
*** =sample_code
```{r}
# Since our dataset is small, let's first directly examine the dataset. We have 10 unique cities with 2 time points of data. Cities that implemented the Housing First policy between 2009-2013 are marked with 1 for Implemented. The rate variable refers to rates in incarceration per 100,000.
    Jail

# Let's use a t.test to compare the rate of incarceration in 2005 among cities that eventually implemented the Housing First Policy to cities that never implemented the Housing First Policy.

#---- Question 1-------------------------------------#
      Solution1<-t.test()
#----------------------------------------------------#

# If you answered Question 1 correctly, you should notice that the rate of incarceration was higher in 2005 among cities that eventually implemented the Housing First policy. Now use a t.test to compare the rate of incarceration in 2015 among cities that implemented the Housing First Policy to cities that never implemented the Housing First Policy.

#---- Question 2-------------------------------------#
      Solution2<-t.test()
#----------------------------------------------------#

# If you answered Question 2 correctly, you should notice that the rate of incarceration was almost equal in 2015 among cities that implemented the Housing First policy and those that did not. If we examined the 2015 data alone, or if we only examined cities that implemented the Housing First Policy we might conclude that implementing the Housing First policy had no effect on incarceration rates. However, there was an increasing trend of incarceration across cities, suggesting that the Housing First policy mitigated increasing rates of incarceration. Let's model this trend with a difference in differences policy. To do this, we simply need to construct a linear model that predicts incarceration based on implementation and year, and with an "interaction" term between implementation and year, which estimates measures whether implementating the policy altered the relationship (or trend) between time and incarceration rates. To include an interaction term in your model, simply multiply the two terms that you want to interact. For example, glm(y ~ x + z + x*z) or glm(y ~ x*z).

#---- Question 3-------------------------------------#
      Solution3<-glm()
#----------------------------------------------------#
      

```
*** =solution
```{r}
Solution1<-t.test(Jail$rate[Jail$Implemented==1 & Jail$Year==2005],Jail$rate[Jail$Implemented==0 & Jail$Year==2005])
Solution2<-t.test(Jail$rate[Jail$Implemented==1 & Jail$Year==2015],Jail$rate[Jail$Implemented==0 & Jail$Year==2015])
Solution3<-glm(rate~Year*Implemented,data=Jail)
```
*** =sct
```{r}
success_msg("Good work! Implementing a difference within differences analysis is relatively easy. We can see from the result of Solution3 that the estimate for Year2015 and Implemented were positive, suggesting that there was an increasing trend in rates of incarceration over time, and cities that implemented the Housing First policy tended to have higher rates of incarceration. However, the interaction term 'Year2015:Implemented' was negative, meaning that over time, cities that implemented the Housing First policy had negative association with incarceration rates relative to those who did not implement the Housing First policy. In other words, cities that implemented the Housing First policy had lower rates of incarceration than one would expect based on common trends")
```





--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:e594e9c9a2
## Graphical Analysis of the Common Trend Assumption and Diff-in-Diffs
*** =video_link
//player.vimeo.com/video/226206681

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:8dc7e4a720
## Interpreting Graphed Time Trends 
Whitney, a fan of the cult pro-environmental film "Birdemic", is interested in whether watching the movie encouraged people to purchase more solar panels. She found a time-series dataset that listed whether people owned solar panels, and whether individuals had watched Birdemic in 2010 (the year the film was released). The results of the interview are plotted to the right. What can we conclude from this graph?
*** =instructions
- Watching birdemic motivated people to buy solar panels.
- Watching birdemic discouraged people from buying solar panels.
*** =pre_exercise_code
```{r}
df<-data.frame(Year=rep(c(2008,2009,2010,2011,2012),2))
df$Treated<-as.factor(rep(c("Yes","No"),each=5))
df$Percent<-c(.02,.023,.026,.027,.028,.01,.013,.016,.02,.024)
library(ggplot2)
p<-ggplot(data=df,aes(x=Year,y=Percent,group=Treated,col=Treated))
p+geom_line()+geom_point()+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  ggtitle("Rate of Solar Panel Ownership by Watching Birdemic")+
  labs(y="Proportion Own Solar Panels",color="Watched Birdemic")
```
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Correct! Rates of solar panel sales for both groups at the same rate prior to Birdemic's release, but the rate of this increase was smaller for those who watched Birdemic following 2010"

test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```





--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:3cf1884e0a
## The Effect of Raising the Minimum Wage on Employment
*** =video_link
//player.vimeo.com/video/226206852



--- type:NormalExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:5326271e36
## Practice Correcting for Changing Measurements
Since society is constantly changing, longitudinal surveys often change their questionnaires to better represent the world we live in. For example, prior to the amendment of the Immigration Act in 1965, only a very small percentage of the U.S. population had Asian heritage. Therefore, very few surveys at the time recorded "Asian American" as a response to questions about race - instead, lumping Asian Americans into an "other" race category. In fact, even the US census had not classified Asian Americans as a distinct ethnic group until 1980. 

Other times these changes can be more arbitrary. For example, a study might ask respondents to state how many hours of TV they tend to watch on a given day on a 1-3 scale, with response option 1 = 0-2 hours, 2=2-5 hours and 3 = 5+ hours. However, that study might increase the number of response options in the following year to allow for more detailed information. For example, respondents might be asked to record a precise estimate of how much TV they watch, rounded to the nearest hour.

While it is always good to have detailed data, changing survey response options can pose problems for data analysts. Our models will not know whether our response options changed unless we explicitly tell our so, therefore, changes in our measurements can significantly confound our model estimates. As an example, modify the `hours` variable in the dataset `TV`, to correct for the somewhat unintuitive findings produced by our difference in differences model which estimates how purchasing a new TV effects hours watched in the following year. Change the response options for `hours` at wave 2 to match the corresponding response options available for `hours` at wave 1. Specifically:

*** =instructions
- If `hours` at wave 2 is less than or equal to 2, set it to 1.
- If `hours` at wave 2 is greater than 2 but less than or equal to 5, set it to 2.
- If `hours` at wave 2 is greater than 5, set it to 3.

*** =pre_exercise_code
```{r}
n=157
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
        qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
        base*round(x/base) 
    } 

set.seed(1)
#Dataframe with year 1
    TV1<-data.frame(ID=1:n,Wave=1,hours=round(rtnorm(n,mean=2,sd=.5,min=1,max=3),0))
    TV1$new<-rbinom(n,1,.33)
#Dataframe with year 2
    TV2<-TV1
    TV2$hours<-ifelse(TV1$hours==1,rtnorm(n,mean=1,sd=.5,min=0,max=2),ifelse(TV1$hours==2,rtnorm(n,mean=3,sd=1,min=2,max=5),ifelse(TV1$hours==3,rtnorm(n,mean=6,sd=1,min=5,max=10),0)))
    TV2$hours<-round(TV2$hours-.5*TV2$new*TV2$hours^2 + 4*TV1$hours*TV2$new,0)
    TV2$hours<-ifelse(TV2$hours<0,0,TV2$hours)
    TV2$Wave<-2
    
    summary(TV1$hours)
    summary(TV2$hours)
#Append data
    TV<-rbind(TV1,TV2)
    TV<-TV[order(TV$ID,TV$Wave),]
    TV$Wave<-factor(TV$Wave)
    rm("TV2")
    rm("TV1")
    
```
*** =sample_code
```{r}
# Let's first get a sense of what our dataset looks like. We have two waves of data, each ID occurs in each wave one time. The "new" variable indicates whether our sample bought a new TV between the two waves. THe hours variable indicates how many hours each respondent used their TV in each wave. During the first wave, respondents were only given three response options for the hours variable, with response option 1 = up to 2 hours, option 2 = above 2 hours 2 and up to 5 hours, and option 3 above 5 hours. During the second wave, respondents simply recorded how many hours they tend to watch TV each day.
    str(TV)
    head(TV)
    summary(TV$hours[TV$Wave==1])
    summary(TV$hours[TV$Wave==2])

# When we estimate a difference in differences model with this data, we see some strange results. We see a substantial increase in hours watched across waves, and a huge effect on hours watched among new TV owners.
    summary(glm(hours~Wave*new,data=TV))

# These odd findings are likely due to the change in our measurement of hours across the waves. Modify the hours variable in Wave 2 to match the hours variable in wave 1. This can be done with the subsetting and/or ifelse functions.

#---- Question 1-------------------------------------#
    TV$hours<-
#----------------------------------------------------#

# If you answered Question 1 correctly, the following difference in differences model should give much more intuitive results. We shouldn't see much of a change hours watched among the entire sample between waves, but we should see a slight increase among those who purchased a new tv.
    summary(glm(hours~Wave*new,data=TV))
```
*** =solution
```{r}
    TV$hours[TV$Wave==2]<-ifelse(TV$hours[TV$Wave==2]<=2,1,ifelse(TV$hours[TV$Wave==2]<=5,2,3))
```
*** =sct
```{r}
test_object("TV")

success_msg("Good work! Implementing a difference within differences analysis is relatively easy. We can see from the result of Solution3 that the estimate for Year2015 and Implemented were positive, suggesting that there was an increasing trend in rates of incarceration over time, and cities that implemented the Housing First policy tended to have higher rates of incarceration. However, the interaction term 'Year2015:Implemented' was negative, meaning that over time, cities that implemented the Housing First policy had negative association with incarceration rates relative to those who did not implement the Housing First policy. In other words, cities that implemented the Housing First policy had lower rates of incarceration than one would expect based on common trends")
```



--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:bd7bd16de8
##Panel Data Terminology
*** =video_link
//player.vimeo.com/video/226207441


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:b9266032e1
## Why use a lagged dependent variable?
Think about what you know about causal inference. What might be an advantage for modeling your data with a lagged dependent variable; that is, a dependent variable measured at a time point after your explanatory variables were measured?
*** =instructions
- Answer 1
- Answer 2
- It helps you more clearly establish causal direction.
- Answer 4
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Try again"
msg3 = "Well done"
msg4 = "Try again"
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```



--- type:NormalExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:6277c6d8ad
## Practice with lagged dependent variables
Walter is the CEO of a large adult coloring books company. As part of a new advertising campaign, Walter wants to publish research which demonstrates that coloring in adult coloring books leads to reduced stress levels. 

When individuals purchase Walter's coloring books online, his company automatically sends a questionnaire asking about his sample's current stress levels. Although respondents reported that coloring in the adult coloring books helped reduce their feelings of stress, the sample's stress levels were about the same as a random sample of individuals who did not buy coloring books. 

Walter hypothesizes that the individuals who purchased the coloring books did not have different stress levels than the general population because they were administered the survey immediately following their purchase. The beneficial effects of using adult coloring books may take time to become noticeable. Therefore, Walter sent a follow-up survey regarding his original sample's stress levels a year later. Using the dataset, `Color`, and help Walter estimate the effect of adult coloring books on stress with his follow up survey. Specifically: 

*** =instructions
- Reproduce Walter's initial analysis by estimating an OLS model that measures the immediate effect of adult coloring books (`books`) on stress (`stress1`), controlling for age (`age`) and gender (`sex`).
- Estimate an OLS model that measures the effect of adult coloring books (`books`) on stress with the lagged dependent variable (`stress2`), controlling for age (`age`) and gender (`sex`).
- Compare the two models to determine which measurement of stress (`stress1` or `stress2`) was more significantly effected by using adult coloring books. 
 
*** =pre_exercise_code
```{r}
set.seed(1)
n=514
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
        qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
        base*round(x/base) 
    } 
#Dataframe
    Color<-data.frame(books=rbinom(n,1,.65))
    Color$age=round(rtnorm(n,mean=30,sd=5,min=25,max=60),0)
    Color$sex=ifelse(rbinom(n,1,.7)==1,"Female","Male")
    Color$stress1=round(rtnorm(n,mean=2,sd=3,min=1,max=10)+Color$age/15+(Color$sex=="Female")/4,0)
    Color$stress2=round(rtnorm(n,mean=1.5,sd=2,min=1,max=10)+Color$age/12+(Color$sex=="Female")/2 - Color$books/2,0)

```
*** =sample_code
```{r}
# Estimate the immediate effect of coloring books, age, and gender on stress (i.e. the dependent variable should be stress1).

#---- Question 1-------------------------------------#
      Solution1<-glm()
#----------------------------------------------------#

# Estimate the lagged effect of coloring books, age, and gender on stress (i.e. the dependent variable should be stress2)

#---- Question 2-------------------------------------#
      Solution2<-glm()
#----------------------------------------------------#

# Which measurement of stress was more significantly effected by the `books` variable: stress1 or stress2? Answer with "stress1" or "stress2" To decide, compare the p-values of the `books` coefficient in Solution1 and Solution2.

#---- Question 3-------------------------------------#
      Solution3<-""
#----------------------------------------------------#

```
*** =solution
```{r}
Solution1<-glm(stress1~books+age+sex,data=Color)
Solution2<-glm(stress2~books+age+sex,data=Color)
summary(Solution1)
summary(Solution2)
Solution3<-"stress2"
```
*** =sct
```{r}
test_object("Solution3")
success_msg("Correct! Estimating an OLS model with a lagged dependent variable is pretty straightforward. While it is not the most sophisticated regression model with panel data, it is a great tool for measuring causal relationships where there is a delay between the cause and expected effect.")
```


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:9f79358c00
## Individual Fixed Effects and Time Varying Treatments
*** =video_link
//player.vimeo.com/video/226207591

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:f5f1233e13
## Confounders in fixed effects models
Suppose we are interested in how exercising in a gym affects a person's self-esteem. We try to gather a random sample of individuals at multiple time points, and examine whether individuals who increased their frequency of exercise in a gym had higher self-esteem. However, when assessing the data, we realize that we oversampled white men, who are known to exercise at gyms at high rates, and who tend to have relatively high self-esteem. If we estimate a fixed effects model with this data, will the fact that we oversampled white men confound our results?

*** =instructions
- Yes
- No
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Correct! Our oversampling of men would clearly confound our estimates in a typical OLS regression model, but since we are only looking at within-person changes, the fact that our sample is biased towards a group of men who tend to exercise and have high self-esteem should not confound our results. As long as the effect of exercise on self-esteem is equal among white men and all other people, and that White men change their rate of exercise as often as the rest of the population, our fixed effects models with this data should accurately reflect the effect of exercise on self-esteem among all people. What is most important is how  the rate of exercise among our sample *changed* over time. If few individuals in our sample increased or decreased their rate of exercise, or if only particular groups tended to change their rates of exercise, our fixed effects models would be biased and have limited statistical power. Individuals whose behavior does not change between waves cannot add to our understanding about how a change in that behavior effects changes in their outcomes."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```



--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:f93e8e963c
## The "Random Assignment" of Changes
*** =video_link
//player.vimeo.com/video/226207674

--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:09b18d2eae
## Violating the random assignment of changes 
Daniel notices that whenever he buys a new WePhone, he feels incredibly happy. Daniel thinks that the world would be a much happier place if everyone owned a new WePhone, and is petitioning the government to subsidize the purchase of all new WePhones. To supplement his petition, Daniel surveys a group of  individuals at two time points. During both waves of the survey, Daniel asks the survey group how happy they are, and whether they own the WePhone 10S (the newest iteration of the WePhone). Daniel conducts a fixed effects model on this dataset, and finds a positive effect of owning a WePhone 10S on happiness (i.e. those who acquired a WePhone 10S in the subsequent wave appeared happier). Why might Daniel's survey be biased?

*** =instructions
- Because the type of person that would buy a WePhone 10S (i.e. be treated) is more likely to be someone who would derive happiness from owning a WePhone 10S.  
- Because people who can afford to buy a WePhone 10S are wealthier and therefore should be happier.
- Because Daniel didn't control for whether buying any new phone would make them happier.
- Because Daniel is a socialist.

*** =sct
```{r}
msg1 = "Correct! Whenever your treatment group is made of people who self-selected into a treatment, you are likely to see some bias. The validity of Daniel's survey rests on his ability to prove that a random sample of the population underwent treatment. In other words, Daniel would need to demonstrate that the individuals who had purchased WePhones between each wave were identical to those who had not purchased WePhones. However, it is pretty likely that people only purchase a WePhone if they expect to derive some sort of utility from the purchase."
msg2 = "This is not a possible source of bias. A fixed effect model only looks at within-person changes; even if people who ended up buying WePhones tended to be wealthier, and even if wealth tended to make people happier, this would not be a source of bias because we are already controlling for differences across individuals."
msg3 = "Even if buying a new phone of any sort makes a person happier, this does not confound or refute Daniel's hypothesis that buying a new WePhone makes people happier."
msg4 = "Try again"
test_mc(correct = 1, feedback_msgs = c(msg1,msg2,msg3,msg4))
```



--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:0fe070c3f3
## Nonlinear time trends 
The popular online retailer, Congo.com, is conducting an experiment to determine whether changing the color scheme of the website's product pages results in higher rates of sales. Congo.com decides to alter the color scheme on the store page for one of its brands of fidget spinners, and use a difference in differences model to determine how the sales of that brand of fidget spinners compared to another popular brand of fidget spinners. However, the sales of fidget spinners during the period of analysis climbed and fell dramatically. The sales trends are indicated on the graph to the right.

Based on this graph and your knowledge about difference in differences models, how did changing the website's color scheme appear to affect sales?

*** =instructions
- Changing the website's color scheme (treatment) increased sales.
- Changing the website's color scheme (treatment) decreased sales.
*** =pre_exercise_code
```{r}
    library(ggplot2)
    
    df<-data.frame(Month=factor(rep(c("March","April","May","June","July","August","September"),2)))
    df$Treated<-as.factor(rep(c("Yes","No"),each=7))
    df$Sales<-c(18.6,35.5,53,62.6,56,42.2,23.5,28.6,50.7,72,84,82,72,54)
    df$Month<-factor(df$Month, levels = c("March","April","May","June","July","August","September"))
    p<-ggplot(data=df,aes(x=Month,y=Sales,group=Treated,col=Treated))
    p+geom_line()+geom_point()+
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
            panel.background = element_blank(), axis.line = element_line(colour = "black"))+
      ggtitle("Fidget Spinner Sales by Experimental Group")+
      labs(y="Sales (in thousands)",color="Changed Color Scheme")
    ```
*** =sct
```{r}
msg1 = "Try again"
msg2 = "Correct! We could verify this answer with a difference in differences model. However, it is important to note that nonlinear trends like these can cause strange results in difference in differences models. We should be very cautious when modeling nonlinear trends."

test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```


--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:8a33d08193
## Does Posting Calorie Counts Lower Calorie Consumption? Causal Inference Bootcamp
*** =video_link
//player.vimeo.com/video/226207727


--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:280768b7d2
## Attrition in Panel Data
Attrition is an inevitability when conducting longitudinal surveys. Many survey respondents refuse to participate in a follow up survey, either to a respondent's lack of interest, or because it is no longer convenient for him to participate in the survey. However, attrition can cause bias. Imagine we conduct a survey about how restaurant reviews effected their number of diners. We gather information from restaurants at two time points, but only 70% of our initial sample participated in our follow up survey. In which of the following circumstances would this attrition be the most cause for concern (i.e. bias our estimates)?
*** =instructions
- If the Restaurants that failed to follow up tended to have worse reviews.
- If the Restaurants that failed to follow up tended to be part of chains.
- If the Restaurants that failed to follow up tended to be vegetarian.
*** =sct
```{r}
msg1 = "Correct. While attrition across all of these traits could cause biases in our estimates, we would be most concerned by non-response that selected our sample on a trait that is related to our variables of interest. Not only does attrition make our sample less representative of the population of restaurants, it might bias our estimates substantially. In this case, what if it turned out that the reason that restaurants that had received worse reviews across the survey were less likely to respond in the second wave is because they went out of business? In this case, our survey would fail to capture information from the restaurants that were most significantly affected by their poor reviews. We would see a much smaller effect from having poor reviews on the number of diners that a restaurant has than if we included those restaurants that failed."
msg2 = "Try again"
msg3 = "Try again"
test_mc(correct = 1, feedback_msgs = c(msg1,msg2,msg3))
```



--- type:MultipleChoiceExercise lang:r xp:50 skills:1 key:ce0e698f11
## Extreme Differences in Control and Treatment 
The mayor of Gettysburg, Alaska is concerned about lead in the town's water. He is considering upgrading the town's water filters, but the city council requires him to provide evidence of the filters' effectiveness in other towns first. The Mayor decides to present a table (illustrated below) showing the amount of lead in the average Gettysburg household's water supply in the past decade (measured in parts per billion) versus the amount of lead in households of the neighboring town, Bristol, which had implemented this filtration system. The mayor also presents a difference in differences model of this data, which shows a significantly signifcant effect of the filtration system in Bristol. Is this data appropriate for conducting a difference in differences model? 


| Town        |   2000   |   2005   |   2010   |
|-------------|---------:|---------:|---------:|
| Gettysburg  |   21 ppb |   23 ppb |   22 ppb |
| Bristol     |13200 ppb | 3700 ppb |  200 ppb |


*** =instructions
- Yes
- No
*** =sct
```{r}
msg1 = "Correct! In this case, the common trends assumption would hold; however, a difference in differences model would violate our assumption that the treatment has a linear effect on our outcome. If the treatment had a linear effect, we would expect implementing a water filter to have a negative amount in the amount of lead in its water supply. While we could try log transforming the data before conducting a difference in differences model, it is still uncertain whether the filtration system would have any effect in a town with such low baseline quantities of led in its water. They mayor of Gettysburg could make a much stronger argument if he found a comparison group that had similar baseline quantities of lead to Gettysburg"
msg2 = "Try again"
test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```



--- type:VideoExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:7ba7ef8e01
## Switchers
*** =video_link
//player.vimeo.com/video/226207860

--- type:NormalExercise lang:r aspect_ratio:62.5 xp:50 skills:1 key:e9cecd77c0
## Practice Running a Fixed and Random Effects Regression Models
Many students at Perry Elementary school write with gel pens. Iris, the school's librarian, is convinced that students could write faster if all the students were required to use ballpoint pens. To test her theory, Iris gets permission to conduct a secondary analysis of an annual student written exam. 

At the end of each school year, students are required to write a three paragraph answer to a short prompt. When students submit their exams, teachers note how long the students took to submit their exams, how many words were written in their exams, and ask the students how many hours of sleep they had slept the previous night. In addition, Iris identified whether the exams were written with a gel or ballpoint pen.

These style exams are given to students three years in a row. Iris was given permission to look at all three of these exams for a single class of students. Since it is possible that students who write with gel pens have different innate writing abilities than those who write with ballpoint pens, Iris decides to only study changes in writing speed for people who switched between using gel pens to ballpoint pens. 

Using the dataset, `Exams`, help Iris estimate the effect of using a ballpoint pen on a student's writing speed with *pooled OLS*, *fixed* and *random* effects models. Specifically:

*** =instructions
- Construct a pooled OLS model that measures the effect of ballpoint pens on student's writing speeds, controlling for age, sex, and hours slept (variables: `pen`,`speed`,`age`,`sex`,`sleep`) .
- Construct a fixed effects model that measures the effect of ballpoint pens on student's writing speeds, controlling for age, sex, and hours slept (variables: `pen`,`speed`,`age`,`sex`,`sleep`).
- Determine whether the absolute value of the Gel pen effect is larger or smaller in the fixed effects model than in the pooled OLS model.
- Construct a random effects model that measures the effect of ballpoint pens on student's writing speeds, controlling for age, sex, and hours slept (variables: `pen`,`speed`,`age`,`sex`,`sleep`).

*** =pre_exercise_code
```{r}
library(plm)
n=521
#Create rnorm function that allows for min and max
  rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
      qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
  }
#Create rounding function that allows to round to numbers above 1
  mround <- function(x,base){ 
          base*round(x/base) 
  } 

set.seed(1)
#Dataframe
  Exams<-data.frame(id=1:n,wave=1)
#year 1:
    #age
        Exams$age<-10+rbinom(n=n,1,.2)
    #sex
        Exams$sex<-ifelse(rbinom(n=n,1,.55)==1,"Female","Male")
    #sleep
        Exams$sleep<-mround(rtnorm(n=n,mean=8,sd=1,min=5,max=9),.5)
    #pen
        Exams$pen<-ifelse(rbinom(n=n,1,.5+ifelse(Exams$sex=="Male",.25,0)+1/Exams$age)==1,"Ballpoint","Gel")
    #speed
        Exams$speed<-round((Exams$age/10+(Exams$sex=="Female")/3+(Exams$sleep/rtnorm(n,2,1,1,3)/4)+(Exams$pen=="Ballpoint")*rtnorm(n,.5,.1,0,1))*2+rnorm(n,3,.5),2)

#year 2:
  Exams2<-data.frame(id=1:n,wave=2)
    Exams2$age<-Exams$age+1
    Exams2$sex<-Exams$sex
    Exams2$sleep<-mround(Exams$sleep+rtnorm(n,0,.3,0,1),.5)
    Exams2$pen<-ifelse(rbinom(n,1,.75)==1,Exams$pen,ifelse(rbinom(n=n,1,.4+ifelse(Exams$sex=="Male",.25,0)+1/Exams$age)==1,"Ballpoint","Gel"))
    Exams2$speed<-round(((Exams2$age/10+(Exams2$sex=="Female")/3+(Exams2$sleep/rtnorm(n,2,1,1,3)/4)+(Exams2$pen=="Ballpoint")*rtnorm(n,.5,.1,0,1))*2+rnorm(n,3,.5))/5+Exams$speed,2)

#year 3:
Exams3<-data.frame(id=1:n,wave=3)
    Exams3$age<-Exams2$age+1
    Exams3$sex<-Exams2$sex
    Exams3$sleep<-mround(Exams2$sleep+rtnorm(n,0,.3,0,1),.5)
    Exams3$pen<-ifelse(rbinom(n,1,.75)==1,Exams2$pen,ifelse(rbinom(n=n,1,.4+ifelse(Exams2$sex=="Male",.25,0)+1/Exams2$age)==1,"Ballpoint","Gel"))
    Exams3$speed<-round(((Exams3$age/10+(Exams3$sex=="Female")/3+(Exams3$sleep/rtnorm(n,2,1,1,3)/4)+(Exams3$pen=="Ballpoint")*rtnorm(n,.5,.1,0,1))*2+rnorm(n,3,.5))/5+Exams2$speed,2)
  
#rbind
    Exams<-rbind(Exams,Exams2)
    Exams<-rbind(Exams,Exams3)
    Exams<-Exams[order(Exams$id,Exams$wave),]

```
*** =sample_code
```{r}
# Before running any models, let's examine the data. The dataset contains seven variables. Wave refers to which date in the time series that we are looking at. Wave 1 refers to the first year the data was collected, whereas wave 3 refers to the last year that the data was collected. Since data was collected three times for each individual, each id variable occurs in the data set 3 times.
    str(Exams)
    head(Exams)

# The meaning of the other variables is pretty intuitive. Sleep refers to the number of hours that the students slept the previous night, and speed refers to the number of words that each student wrote per a minute.
    summary(Exams$sleep)
    summary(Exams$speed)

# Run a typical OLS model on the dataset, treating each repeated observation as an independent person (i.e. pooling the data), where speed is the dependent variable, pen is the independent variable, and where we have control variables for age, sex, and sleep. For reference, the syntax for glm models is glm(y ~ x + z1 + z2 + z3, data=df), where y is the dependent variable, x is the independent variable, z1-z3 are control variables, and df is the data frame. You do not need to use the id or wave variables in this model.

#---- Question 1-------------------------------------#
      Solution1<-glm()
#----------------------------------------------------#
  
# If you answered question 1 correctly, you should see a large negative effect from using gel pens. However, when we pool the data this way, we are treating repeated observations as separate people. This is not true. Pooling our data this way will bias our parameter estimates, especially if there is variation in each student's underlying writing ability and these variations are correlated with whether they use gel pens.
    summary(Solution1)
    
# Now let's try estimating a fixed effects model. Random effects models work similarly to OLS models, except that it also controls for how observations in our sample are related. Basically, we want to control for student's different latent writing speeds, and only look at how switching between a gel and ballpoint pen effected their writing speeds compared to those who did not switch pens, To estimate a fixed effects model, we need to use the plm function. The syntax is  identical to glm, except that after the data statement, we specify how the data are grouped (by id and wave) and what type of effect that we want to examine (within person changes). Fill in the front part of the plm model so that it estimates the effect of using a gel pen on writing speed while controlling for age, sex, and sleep.
    
#---- Question 2-------------------------------------#
      Solution2<-plm(,index=c("id", "wave"), model="within")
#----------------------------------------------------#

# If you answered question 2 correctly, you should notice that the model only gave us parameter estimates for sleep and gel pens. This is because the sex of students did not change across any years (again, we are only looking at how changes within individuals affected their writing speeds), and because the change in age was uniform across years for all respondents (that is, there was no variation in how student's ages changed across individuals - everyone grew one year older each wave). You should also notice that the parameter estimate for gel pens differs from the first model. Is the absolute value of the effect of gel pens larger or smaller in solution2 than in solution1. Answer with "Larger" or "Smaller".

#---- Question 3-------------------------------------#
      Solution3<-""
#----------------------------------------------------#

# Although fixed effects models are very reliable, they often require large sample sizes to find statistically significant results, and they often exclude estimating effect that would be interesting to report in a regression model (for example, the effect of age and sex on writing speed). In such cases, we often use random effects models instead. Random effects models are almost identical to fixed effects models, except they make the somewhat strong assumption that the individual specific effects are uncorrelated with your other parameters. In this example, a random effects model assumes that every individual has a latent writing speed that is uncorrelated with anything else. Factors like age and sex simply improve their writing speeds. Estimate a random effects model that groups individuals by id and wave, but that also controls for age, sex, and sleep. The syntax should be identical to that in Question 2, except that the "model" parameter in the plm function should be switched from "within" to "random".

#---- Question 4-------------------------------------#
      Solution4<-plm()
#----------------------------------------------------#

```
*** =solution
```{r}
#models    
    Solution1<-glm(speed~pen+sleep+sex+age,data=Exams)
    Solution2<-plm(speed ~ age + sex + sleep + pen, data=Exams, index=c("id", "wave"), model="within")
    Solution3<-"Larger"
    Solution4<-plm(speed ~ age + sex + sleep + pen, data=Exams, index=c("id", "wave"), model="random")
    
```
*** =sct
```{r}
test_object("Solution3")
success_msg("Good work! You now know the basics to estimating fixed and random effects models with panel data. As you can see, these models often give very different results than typical pooled OLS models, and their estimates tend to be much more robust. You may still be wondering when you should use random versus fixed effects models. In general, if you can find statistically significant effects with fixed effects models, they are preferable to random effects models. However, there are a variety of tools available for comparing whether you get any benefit from using a fixed effects model (e.g. the Hausman test). In general, use you intution and see what other people have done in similar situations!")
```

















